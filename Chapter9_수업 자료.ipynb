{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzum4Xt0Aa8zlpF5lh463o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/music-ai-644/AI_Study_2022/blob/main/Chapter9_%EC%88%98%EC%97%85%20%EC%9E%90%EB%A3%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 영화 리뷰 데이터셋\n",
        "## 텍스트 분류하기 "
      ],
      "metadata": {
        "id": "KbCz2l36VL-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터 불러오기 "
      ],
      "metadata": {
        "id": "Ym09lvkZVYHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=200)\n",
        "# skip_top 제일 많이 나오는 단어 20개는 삭제 (a, the 같은 관사일 수 있음)\n",
        "# num_words 단어의 개수를 설정 "
      ],
      "metadata": {
        "id": "mdO90EZpUtN0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터셋 확인 "
      ],
      "metadata": {
        "id": "8MJvsgG2Vhib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figure3](https://github.com/music-ai-644/AI_Study_2022/blob/main/figure/Chapter9_3.PNG?raw=true)"
      ],
      "metadata": {
        "id": "KQUSH588Z281"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 인터넷 영화 평점 사이트의 댓글 데이터 셋 \n",
        "- 리뷰 하나가 들어왔을 때 문장(문자열)을 보고 긍정(1) 인지, 부정(0)인지 예측하는 학습에 사용\n",
        "- 이러한 task를 감성 분석(sentimental analysis)이라고 함"
      ],
      "metadata": {
        "id": "mnuN5CA8Z8W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_all.shape, y_train_all.shape)"
      ],
      "metadata": {
        "id": "zNwJOBz_VLM9",
        "outputId": "441dd51e-3417-4669-d91c-aabcc723f1ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figure4](https://github.com/music-ai-644/AI_Study_2022/blob/main/figure/Chapter9_4.PNG?raw=true)"
      ],
      "metadata": {
        "id": "3ZcZDUuBahLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫 번째 sequence의 길이 : \", len(x_train_all[0]))\n",
        "print(\"두 번째 sequence의 길이 : \", len(x_train_all[1]))"
      ],
      "metadata": {
        "id": "lOfjk4sGVm2t",
        "outputId": "377080a2-d4e8-46ca-f487-652b94693a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 sequence의 길이 :  218\n",
            "두 번째 sequence의 길이 :  189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫 번째 sequence의 타겟값 : \", y_train_all[0])\n",
        "print(\"두 번째 sequence의 타겟값 : \", y_train_all[1])"
      ],
      "metadata": {
        "id": "y5cHBGsHVouJ",
        "outputId": "938018c0-e851-4a4f-d5ce-ccc164e0c496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 sequence의 타겟값 :  1\n",
            "두 번째 sequence의 타겟값 :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5YWWgCuwYXld"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "lengths = np.array([len(x) for x in x_train])  # train set의 sequence의 길이들을 모음 \n",
        "print(\"훈련 데이터 셋 길이의 평균   : \", np.mean(lengths))\n",
        "print(\"훈련 데이터 셋 길이의 중간값 : \", np.median(lengths))\n",
        "\n",
        "plt.hist(lengths)\n",
        "plt.grid()\n",
        "plt.xlabel(\"length\")\n",
        "plt.ylabel(\"frequency\")"
      ],
      "metadata": {
        "id": "Mz1wX7Xra0F0",
        "outputId": "7827c811-0357-464c-9261-74180f1509aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 셋 길이의 평균   :  238.4934\n",
            "훈련 데이터 셋 길이의 중간값 :  178.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaCElEQVR4nO3df7RV5X3n8fenEI0aDajtHQusXpLQZIg0ltxBJunKuit2AZo0OJ3E4LL1xjBlZkoaO0MmgWZWSbV2NBnihGlii5UEM1Z0jBlZVYvUeFaWXYEIiviDGm4QAxSlCYgenJrCfOeP/dz05ObcyznPPT/uuefzWuuss/d3P3vv53vOhe/aP86zFRGYmZnl+Ll2d8DMzDqXi4iZmWVzETEzs2wuImZmls1FxMzMsk1udwda7fzzz4/e3t661zt+/DhnnXVW4zs0jjnn7tCNOUN35j2WnHfs2PHDiPj54fGuKyK9vb1s37697vVKpRL9/f2N79A45py7QzfmDN2Z91hylvRCtbhPZ5mZWTYXETMzy+YiYmZm2VxEzMwsm4uImZllcxExM7NsLiJmZpataUVE0npJhyU9XWXZCkkh6fw0L0lrJQ1K2iVpbkXbAUl70mugIv5uSU+lddZKUrNyMTOz6pp5JPI1YNHwoKQZwALgBxXhS4FZ6bUMuCW1PRdYDVwMzANWS5qa1rkF+J2K9X5mX2Zm1lxN+8V6RHxbUm+VRTcDnwbuq4gtBm6P4glZWyVNkXQB0A9siYgjAJK2AIsklYBzImJrit8OXA482JxsCr0r72/m5ke078YPtGW/Zman0tJhTyQtBg5GxJPDzj5NA/ZXzB9IsdHiB6rER9rvMoojHHp6eiiVSnX3vVwus2LOybrXa4Sc/jZCuVxu277bxTl3j27Muxk5t6yISDoT+AOKU1ktFRHrgHUAfX19kTN2TKlUYs2jxxvcs9rsu6q/Lfv12ELdoRtzhu7Muxk5t/LurLcCM4EnJe0DpgOPS/oXwEFgRkXb6Sk2Wnx6lbiZmbVQy4pIRDwVEb8QEb0R0UtxCmpuRLwIbAKuTndpzQeORcQhYDOwQNLUdEF9AbA5LXtF0vx0V9bV/PQ1FjMza4Fm3uJ7J/Ad4O2SDkhaOkrzB4C9wCBwK/C7AOmC+vXAY+l13dBF9tTmL9I636fJF9XNzOxnNfPurCtPsby3YjqA5SO0Ww+srxLfDlw4tl6amdlY+BfrZmaWzUXEzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWzUXEzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWzUXEzMyyuYiYmVk2FxEzM8vWtCIiab2kw5Keroh9QdLfSdol6ZuSplQsWyVpUNJzkhZWxBel2KCklRXxmZK2pfhdkk5rVi5mZlZdM49EvgYsGhbbAlwYEb8CfA9YBSBpNrAEeGda5yuSJkmaBHwZuBSYDVyZ2gLcBNwcEW8DjgJLm5iLmZlV0bQiEhHfBo4Miz0UESfS7FZgeppeDGyMiNcj4nlgEJiXXoMRsTcifgxsBBZLEvB+4J60/gbg8mblYmZm1bXzmsjHgQfT9DRgf8WyAyk2Uvw84OWKgjQUNzOzFprcjp1K+ixwArijRftbBiwD6OnpoVQq1b2NcrnMijknG9yz2uT0txHK5XLb9t0uzrl7dGPezci55UVE0seADwKXRESk8EFgRkWz6SnGCPEfAVMkTU5HI5Xtf0ZErAPWAfT19UV/f3/d/S6VSqx59Hjd6zXCvqv627LfUqlEzmfVyZxz9+jGvJuRc0tPZ0laBHwa+FBEvFaxaBOwRNLpkmYCs4DvAo8Bs9KdWKdRXHzflIrPI8CH0/oDwH2tysPMzArNvMX3TuA7wNslHZC0FPhT4Gxgi6Sdkv4MICKeAe4GngX+GlgeESfTUcYngM3AbuDu1BbgM8B/ljRIcY3ktmblYmZm1TXtdFZEXFklPOJ/9BFxA3BDlfgDwANV4nsp7t4yM7M28S/Wzcwsm4uImZllcxExM7NsLiJmZpbNRcTMzLK5iJiZWTYXETMzy+YiYmZm2VxEzMwsm4uImZllcxExM7NsLiJmZpbNRcTMzLK5iJiZWTYXETMzy+YiYmZm2VxEzMwsm4uImZllcxExM7NsLiJmZpbNRcTMzLI1rYhIWi/psKSnK2LnStoiaU96n5rikrRW0qCkXZLmVqwzkNrvkTRQEX+3pKfSOmslqVm5mJlZdc08EvkasGhYbCXwcETMAh5O8wCXArPSaxlwCxRFB1gNXAzMA1YPFZ7U5ncq1hu+LzMza7KmFZGI+DZwZFh4MbAhTW8ALq+I3x6FrcAUSRcAC4EtEXEkIo4CW4BFadk5EbE1IgK4vWJbZmbWIpNbvL+eiDiUpl8EetL0NGB/RbsDKTZa/ECVeFWSllEc4dDT00OpVKq74+VymRVzTta9XiPk9LcRyuVy2/bdLs65e3Rj3s3IudVF5CciIiRFi/a1DlgH0NfXF/39/XVvo1QqsebR4w3uWW32XdXflv2WSiVyPqtO5py7Rzfm3YycW3131kvpVBTp/XCKHwRmVLSbnmKjxadXiZuZWQu1uohsAobusBoA7quIX53u0poPHEunvTYDCyRNTRfUFwCb07JXJM1Pd2VdXbEtMzNrkaadzpJ0J9APnC/pAMVdVjcCd0taCrwAXJGaPwBcBgwCrwHXAETEEUnXA4+ldtdFxNDF+t+luAPsDODB9DIzsxZqWhGJiCtHWHRJlbYBLB9hO+uB9VXi24ELx9JHMzMbG/9i3czMsrmImJlZNhcRMzPL5iJiZmbZXETMzCybi4iZmWVzETEzs2wuImZmls1FxMzMsrmImJlZtlMWEUk7JC2veKKgmZkZUNuRyEeBXwQek7RR0kI/z9zMzKCGIhIRgxHxWeCXgb+kGAzxBUl/lJ6BbmZmXaqmayKSfgVYA3wB+AbwEeAV4FvN65qZmY13pxwKXtIO4GXgNmBlRLyeFm2T9N5mds7MzMa3Wp4n8pGI2FttQUT8ZoP7Y2ZmHaSW01n/TtKUoZn0qNo/bmKfzMysQ9RSRC6NiJeHZiLiKMWjbM3MrMvVUkQmSTp9aEbSGcDpo7Q3M7MuUcs1kTuAhyV9Nc1fA2xoXpfMzKxT1PI7kZuAG4B/mV7XR8Tnx7JTSf9J0jOSnpZ0p6Q3SpopaZukQUl3STottT09zQ+m5b0V21mV4s9JWjiWPpmZWf1q+p1IRDwYEZ9Kr81j2aGkacAngb6IuBCYBCwBbgJujoi3AUeBpWmVpcDRFL85tUPS7LTeO4FFwFckTRpL38zMrD61jJ31m5L2SDom6RVJr0p6ZYz7nQycIWkycCZwCHg/cE9avgG4PE0v5p9Pn90DXJKGXVkMbIyI1yPieWAQmDfGfpmZWR1quSbyeeA3ImJ3I3YYEQcl/XfgB8D/BR4CdgAvR8SJ1OwAMC1NTwP2p3VPSDoGnJfiWys2XbnOT5G0DFgG0NPTQ6lUqrvf5XKZFXNO1r1eI+T0txHK5XLb9t0uzrl7dGPezci5liLyUqMKCBS/M6E4iphJ8Uv4/01xOqppImIdsA6gr68v+vv7695GqVRizaPHG9yz2uy7qr8t+y2VSuR8Vp3MOXePbsy7GTnXUkS2S7oL+D/A0JAnRMS9mfv8deD5iPgHAEn3Au8FpkianI5GpgMHU/uDwAzgQDr99WbgRxXxIZXrmJlZC9RyYf0c4DVgAfAb6fXBMezzB8B8SWemaxuXAM8CjwAfTm0GgPvS9KY0T1r+rYiIFF+S7t6aCcwCvjuGfpmZWZ1OeSQSEdc0cocRsU3SPcDjwAngCYpTTfcDG9OQKk9QDPhIev+6pEHgCMUdWUTEM5LupihAJ4DlEdGeixZmZl2qllF8fxm4BeiJiAvTsPAfiojs8bMiYjWwelh4L1XuroqIf6QYer7adm6g+A2LmZm1QS2ns24FVgH/BBARu0hHA2Zm1t1qKSJnRsTwaw0nqrY0M7OuUksR+aGktwIBIOnDFD8ONDOzLlfLLb7LKS58v0PSQeB54Lea2iszM+sItdydtRf4dUlnAT8XEa82v1tmZtYJark76w+HzQMQEdc1qU9mZtYhajmdVTnWxxspfmjYsGFQzMysc9VyOmtN5XwaPHFMw8GbmdnEUNPzRIY5k2KcKjMz63K1XBN5inR7L8UDpH4e8PUQMzOr6ZpI5WCLJyiGhvePDc3MrKYiMvyW3nOG7tACiIgjDe2RmZl1jFqKyOMUz+04CgiYQjGcOxSnud7SnK6Zmdl4V8uF9S0Uj8c9PyLOozi99VBEzIwIFxAzsy5WSxGZHxEPDM1ExIPAe5rXJTMz6xS1nM76e0n/Ffhfaf4q4O+b1yUzM+sUtRyJXElxW+83gXvT9JXN7JSZmXWGWn6xfgS4VtJZEXH8VO3NzKx7nPJIRNJ7JD1LGi9L0rskfaXpPTMzs3GvltNZNwMLgR8BRMSTwPua2SkzM+sMNY2dFRH7h4VONqEvZmbWYWopIvslvQcISW+Q9CnGOBS8pCmS7pH0d5J2S/rXks6VtEXSnvQ+NbWVpLWSBiXtkjS3YjsDqf0eSQNj6ZOZmdWvliLyHygekTsNOAhclObH4kvAX0fEO4B3URSllcDDETELeDjNA1wKzEqvZcAtAJLOBVYDFwPzgNVDhcfMzFpj1LuzJE0CvhQRVzVqh5LeTHFN5WMAEfFj4MeSFgP9qdkGoAR8BlgM3B4RAWxNRzEXpLZbhsbukrQFWATc2ai+mpnZ6EYtIhFxUtIvSTot/WffCDOBfwC+KuldwA7gWqAnIg6lNi8CPWl6GlB5TeZAio0U/xmSllEcxdDT00OpVKq70+VymRVz2nMpKKe/jVAul9u273Zxzt2jG/NuRs61/GJ9L/C3kjZR8ajciPjiGPY5F/i9iNgm6Uv886mroW2HpKi6doaIWAesA+jr64v+/v66t1EqlVjzaHt+JrPvqv627LdUKpHzWXUy59w9ujHvZuQ84jURSV9Pkx8C/iq1PbvilesAcCAitqX5eyiKykvpNBXp/XBafpBiFOEh01NspLiZmbXIaEci75b0ixTDvv/PRu0wIl6UtF/S2yPiOeAS4Nn0GgBuTO/3pVU2AZ+QtJHiIvqxiDgkaTPwJxUX0xcAqxrVTzMzO7XRisifUdwlNRPYXhEXY3+OyO8Bd0g6jeJ02TUURzp3S1oKvABckdo+AFwGDAKvpbZExBFJ1wOPpXbX+QFZZmatNWIRiYi1wFpJt0TEf2zkTiNiJ9BXZdElVdoGI9xSHBHrgfWN7JuZmdXulL8TaXQBMTOziaOmYU/MzMyqcRExM7NsLiJmZpbNRcTMzLK5iJiZWTYXETMzy+YiYmZm2VxEzMwsm4uImZllcxExM7NsLiJmZpbNRcTMzLK5iJiZWTYXETMzy+YiYmZm2VxEzMwsm4uImZllcxExM7NsIz5j3caP3pX3t2W/K+acoL8tezazTtG2IxFJkyQ9Iemv0vxMSdskDUq6S9JpKX56mh9My3srtrEqxZ+TtLA9mZiZda92ns66FthdMX8TcHNEvA04CixN8aXA0RS/ObVD0mxgCfBOYBHwFUmTWtR3MzOjTUVE0nTgA8BfpHkB7wfuSU02AJen6cVpnrT8ktR+MbAxIl6PiOeBQWBeazIwMzNo3zWR/wF8Gjg7zZ8HvBwRJ9L8AWBamp4G7AeIiBOSjqX204CtFdusXOenSFoGLAPo6emhVCrV3eFyucyKOSfrXq+T9ZxB1mfVycrlsnPuEt2YdzNybnkRkfRB4HBE7JDU34p9RsQ6YB1AX19f9PfXv9tSqcSaR483uGfj24o5J7gi47PqZKVSiZy/j07WjTlDd+bdjJzbcSTyXuBDki4D3gicA3wJmCJpcjoamQ4cTO0PAjOAA5ImA28GflQRH1K5jpmZtUDLr4lExKqImB4RvRQXxr8VEVcBjwAfTs0GgPvS9KY0T1r+rYiIFF+S7t6aCcwCvtuiNMzMjPH1O5HPABsl/THwBHBbit8GfF3SIHCEovAQEc9Iuht4FjgBLI+I7rpoYWbWZm0tIhFRAkppei9V7q6KiH8EPjLC+jcANzSvh2ZmNhoPe2JmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWzUXEzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWzUXEzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC0vIpJmSHpE0rOSnpF0bYqfK2mLpD3pfWqKS9JaSYOSdkmaW7GtgdR+j6SBVudiZtbt2nEkcgJYERGzgfnAckmzgZXAwxExC3g4zQNcCsxKr2XALVAUHWA1cDEwD1g9VHjMzKw1Wl5EIuJQRDyepl8FdgPTgMXAhtRsA3B5ml4M3B6FrcAUSRcAC4EtEXEkIo4CW4BFLUzFzKzrTW7nziX1Ar8KbAN6IuJQWvQi0JOmpwH7K1Y7kGIjxavtZxnFUQw9PT2USqW6+1oul1kx52Td63WynjPI+qw6Wblcds5dohvzbkbObSsikt4EfAP4/Yh4RdJPlkVESIpG7Ssi1gHrAPr6+qK/v7/ubZRKJdY8erxRXeoIK+ac4IqMz6qTlUolcv4+Olk35gzdmXczcm7L3VmS3kBRQO6IiHtT+KV0mor0fjjFDwIzKlafnmIjxc3MrEXacXeWgNuA3RHxxYpFm4ChO6wGgPsq4lenu7TmA8fSaa/NwAJJU9MF9QUpZmZmLdKO01nvBX4beErSzhT7A+BG4G5JS4EXgCvSsgeAy4BB4DXgGoCIOCLpeuCx1O66iDjSmhTMzAzaUEQi4lFAIyy+pEr7AJaPsK31wPrG9c7MzOrhX6ybmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWra0DMNr417vy/rbsd9+NH2jLfs2sPj4SMTOzbC4iZmaWzUXEzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiJmZZXMRMTOzbC4iZmaWzcOe2LjUruFWVsw5QX9b9mzWmXwkYmZm2VxEzMwsW8cXEUmLJD0naVDSynb3x8ysm3R0EZE0CfgycCkwG7hS0uz29srMrHt0+oX1ecBgROwFkLQRWAw829ZeWUfzM1TMatfpRWQasL9i/gBw8fBGkpYBy9JsWdJzGfs6H/hhxnod65POuaV0Uzv2CnTh95x0Y95jyfmXqgU7vYjUJCLWAevGsg1J2yOir0Fd6gjOuTt0Y87QnXk3I+eOviYCHARmVMxPTzEzM2uBTi8ijwGzJM2UdBqwBNjU5j6ZmXWNjj6dFREnJH0C2AxMAtZHxDNN2t2YTod1KOfcHboxZ+jOvBuesyKi0ds0M7Mu0emns8zMrI1cRMzMLJuLyClM5GFVJO2T9JSknZK2p9i5krZI2pPep6a4JK1Nn8MuSXPb2/vaSVov6bCkpytidecpaSC13yNpoB251GqEnD8n6WD6vndKuqxi2aqU83OSFlbEO+bvX9IMSY9IelbSM5KuTfEJ+12PknPrvuuI8GuEF8XF+u8DbwFOA54EZre7Xw3Mbx9w/rDY54GVaXolcFOavgx4EBAwH9jW7v7Xkef7gLnA07l5AucCe9P71DQ9td251Znz54BPVWk7O/1tnw7MTH/zkzrt7x+4AJibps8Gvpdym7Df9Sg5t+y79pHI6H4yrEpE/BgYGlZlIlsMbEjTG4DLK+K3R2ErMEXSBe3oYL0i4tvAkWHhevNcCGyJiCMRcRTYAixqfu/zjJDzSBYDGyPi9Yh4Hhik+NvvqL//iDgUEY+n6VeB3RSjWkzY73qUnEfS8O/aRWR01YZVGe0L6jQBPCRpRxoaBqAnIg6l6ReBnjQ90T6LevOcKPl/Ip26WT90WocJmLOkXuBXgW10yXc9LGdo0XftItLdfi0i5lKMgrxc0vsqF0Zx/Dvh7wHvljyBW4C3AhcBh4A17e1Oc0h6E/AN4Pcj4pXKZRP1u66Sc8u+axeR0U3oYVUi4mB6Pwx8k+KQ9qWh01Tp/XBqPtE+i3rz7Pj8I+KliDgZEf8PuJXi+4YJlLOkN1D8Z3pHRNybwhP6u66Wcyu/axeR0U3YYVUknSXp7KFpYAHwNEV+Q3ejDAD3pelNwNXpjpb5wLGKUwSdqN48NwMLJE1NpwYWpFjHGHYN699QfN9Q5LxE0umSZgKzgO/SYX//kgTcBuyOiC9WLJqw3/VIObf0u2733QXj/UVxB8f3KO5c+Gy7+9PAvN5CcQfGk8AzQ7kB5wEPA3uAvwHOTXFRPADs+8BTQF+7c6gj1zspDun/ieJc79KcPIGPU1yIHASuaXdeGTl/PeW0K/0HcUFF+8+mnJ8DLq2Id8zfP/BrFKeqdgE70+uyifxdj5Jzy75rD3tiZmbZfDrLzMyyuYiYmVk2FxEzM8vmImJmZtlcRMzMLJuLiFkDSSo3YZsXDRuF9XOSPtXo/ZjlcBExG/8uoriH32zccRExaxJJ/0XSY2kQvD9KsV5JuyXdmp7/8JCkM9Kyf5Xa7pT0BUlPp18PXwd8NMU/mjY/W1JJ0l5Jn2xTimYuImbNIGkBxZAS8yiOJN5dMcDlLODLEfFO4GXg36b4V4F/HxEXAScBohiW+w+BuyLiooi4K7V9B8WQ5fOA1Wn8JLOWcxExa44F6fUE8DjFf/qz0rLnI2Jnmt4B9EqaApwdEd9J8b88xfbvj+KZED+kGFCw5xTtzZpicrs7YDZBCfhvEfHnPxUsnvnwekXoJHBGxvaHb8P/lq0tfCRi1hybgY+n5zwgaZqkXxipcUS8DLwq6eIUWlKx+FWKR5+ajTsuImZNEBEPUZyS+o6kp4B7OHUhWArcKmkncBZwLMUfobiQXnlh3Wxc8Ci+ZuOEpDdFRDlNr6QYvvvaNnfLbFQ+j2o2fnxA0iqKf5cvAB9rb3fMTs1HImZmls3XRMzMLJuLiJmZZXMRMTOzbC4iZmaWzUXEzMyy/X9ky2lw/ZeIDQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 샘플 길이 맞추고 원-핫 인코딩하기"
      ],
      "metadata": {
        "id": "FjP7djoYXqBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figure1](https://github.com/music-ai-644/AI_Study_2022/blob/main/figure/Chapter9_1.PNG?raw=true)\n",
        "- 순환 신경망의 경우, sequence의 길이가 짧은 경우, 뒤에 하는 것이 아니라 앞에 함\n",
        "- 텍스트 분류를 위해서 신경망의 가장 마지막 output을 사용하게 되는데, 이 때 뒤에 패딩한 값(zero 혹은 기타)이 영향을 주게 되어 실제 데이터와 무관한 값이 나올 수 있음\n",
        "\n",
        "![figure2](https://github.com/music-ai-644/AI_Study_2022/blob/main/figure/Chapter9_2.PNG?raw=true)"
      ],
      "metadata": {
        "id": "hkSid-9ZWilO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence \n",
        "\n",
        "maxlen = 200  # 배치 내의 sequence의 길이를 최대 100으로 함 \n",
        "x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_valid_seq = sequence.pad_sequences(x_valid, maxlen=maxlen)\n",
        "x_test_seq = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "FSZl_CHBV411"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![figure5](https://github.com/music-ai-644/AI_Study_2022/blob/main/figure/Chapter9_5.PNG?raw=true)"
      ],
      "metadata": {
        "id": "qxLeyDb9bz_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"훈련 데이터 셋의 형태 : \", np.shape(x_train_seq))"
      ],
      "metadata": {
        "id": "IOZ8ZEzrYtSh",
        "outputId": "f0f2339c-e4fe-4d65-8ac0-62959849f621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 셋의 형태 :  (20000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "# x_train_onehot = to_categorical(x_train_seq)\n",
        "# x_valid_onehot = to_categorical(x_valid_seq)"
      ],
      "metadata": {
        "id": "u_WktqK9YDHa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"훈련 데이터 셋의 타겟 : \", np.shape(x_train_seq))  # (전체 샘플 개수, sequence 길이, 단어의 개수)\n",
        "print(\"평가 데이터 셋의 타겟 : \", np.shape(x_valid_seq))  # (전체 샘플 개수, sequence 길이, 단어의 개수)"
      ],
      "metadata": {
        "id": "kjLL9aKgY-NZ",
        "outputId": "bbad148b-270d-4c60-dd1a-fca3b030cca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 셋의 타겟 :  (20000, 200)\n",
            "평가 데이터 셋의 타겟 :  (5000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x_train_torch = torch.FloatTensor(x_train_seq)\n",
        "y_train_torch = torch.FloatTensor(y_train)\n",
        "x_valid_torch = torch.FloatTensor(x_valid_seq)\n",
        "y_valid_torch = torch.FloatTensor(y_valid) \n",
        "x_test_torch = torch.FloatTensor(x_test_seq)\n",
        "y_test_torch = torch.FloatTensor(y_test) "
      ],
      "metadata": {
        "id": "JiSTADR5ZDhV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn \n",
        "from torch.utils.data import Dataset, DataLoader "
      ],
      "metadata": {
        "id": "quyQx0-DdXey"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x_data = x \n",
        "    self.y_data = y \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = self.x_data[index]\n",
        "    y = self.y_data[index]\n",
        "    return x, y\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    x, y = zip(*batch)\n",
        "    return x, y \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n"
      ],
      "metadata": {
        "id": "C6M5hK5-dnAP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = IMDBDataset(x_train_torch, y_train_torch)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True)\n",
        "valid_dataset = IMDBDataset(x_valid_torch, y_valid_torch)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=20, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "N5cD5sEVIPTC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.n_layer = 1\n",
        "    self.n_hidden = 100\n",
        "    self.embedding = nn.Embedding(200, self.n_hidden)\n",
        "    self.rnn = nn.RNN(self.n_hidden, self.n_hidden)\n",
        "    self.net = nn.Sequential(nn.Linear(self.n_hidden, 1), nn.Sigmoid())\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, hidden = self.rnn(x, hidden)\n",
        "    predicts = self.net(output)\n",
        "    return predicts[-1, :, :], hidden\n",
        "\n",
        "  def predict(self, x):\n",
        "    predicts = []\n",
        "    len_x = x.size(1)\n",
        "    for i in range(len_x):\n",
        "      pred = model(x[:, i].unsqueeze(1))\n",
        "      predicts.append(pred.data.numpy()[0])\n",
        "    return np.array(predicts) > 0.5\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    h0 = torch.zeros(self.n_layer, batch_size, self.n_hidden)\n",
        "    return h0\n",
        "    "
      ],
      "metadata": {
        "id": "IP5CcmxSM-az"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "import random \n",
        "\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "\n",
        "model = MyModel() \n",
        "model.train()\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "global_step = 0 \n",
        "for epoch in range(10):\n",
        "  t = tqdm(dataloader, ncols=100)\n",
        "  hidden = model.init_hidden(8)\n",
        "  for i, batch in enumerate(t):\n",
        "    x_batch = batch[0]\n",
        "    y_batch = batch[1]\n",
        "    x_batch = x_batch.transpose(0, 1)\n",
        "    predicts, hidden = model(x_batch.long(), hidden)\n",
        "    loss = criterion(predicts[:,0], y_batch)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    global_step += 1\n",
        "    t.set_description(\"epoch: {} | global_step: {:8d} | loss: {:.4f}\".format(epoch + 1, global_step, loss))\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    predicts = model.predict(x_valid_torch.transpose(0, 1).long())\n",
        "    result = np.mean(predicts == y_test)\n",
        "    print(\"정확도 : {:%}\".format(result))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "QTrbnA3qI4Si",
        "outputId": "7446cf33-dfdc-4617-e3b6-502e1e91054d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 1 | global_step:        1 | loss: 0.6373:   0%|             | 1/2500 [00:00<11:14,  3.70it/s]/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py:175: UserWarning: Error detected in TanhBackward0. Traceback of forward call that caused the error:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-47-acaf30adcc15>\", line 23, in <module>\n",
            "    predicts, hidden = model(x_batch.long(), hidden)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-46-ce2d405fa606>\", line 12, in forward\n",
            "    output, hidden = self.rnn(x, hidden)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\", line 473, in forward\n",
            "    self.batch_first)\n",
            " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:102.)\n",
            "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "epoch: 1 | global_step:        1 | loss: 0.6373:   0%|             | 1/2500 [00:00<22:39,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-acaf30adcc15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.mean(predicts(x_test_torch) == y_test)\n",
        "print(\"epoch: {} | global_step: {} | valid acc: {:%}\".format(epoch + 1, global_step, acc))"
      ],
      "metadata": {
        "id": "IKz-kkBlJxB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LhCsVr_bYPIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}