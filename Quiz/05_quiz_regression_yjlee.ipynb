{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/coder/.local/lib/python3.6/site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.17.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (41.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn \n",
    "import pathlib\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/coder/.keras/datasets/auto-mpg.data'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(dataset[column_names], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(idxs=[2,3]):\n",
    "    column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                    'Acceleration', 'Model Year', 'Origin']\n",
    "    raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                        na_values = \"?\", comment='\\t',\n",
    "                        sep=\" \", skipinitialspace=True)\n",
    "\n",
    "    ds = raw_dataset.copy().to_numpy()\n",
    "    dataset = []\n",
    "\n",
    "    for i, element in enumerate(ds):\n",
    "        is_nan = False\n",
    "        for x in element:\n",
    "            if np.isnan(x):\n",
    "                # print('here', i )\n",
    "                is_nan=True\n",
    "        \n",
    "        if is_nan is False:\n",
    "            dataset.append(element)\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "    x = dataset[:, idxs]\n",
    "    y = dataset[:, 0]\n",
    "    return x, y\n",
    "\n",
    "def norm(x, x_mean=None, x_std=None):\n",
    "    if x_mean is None:\n",
    "        x_mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        x_std = torch.std(x, dim=0, keepdim=True)\n",
    "\n",
    "    x = (x - x_mean) / x_std\n",
    "    return x, x_mean, x_std\n",
    "\n",
    "def dnorm(x, x_mean=None, x_std=None):\n",
    "    output = x * x_std + x_mean\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class RegressionNeuron2(nn.Module):\n",
    "    def __init__(self, in_dim=2, n_hidden=60, learning_rate=1e-2, w1=1.11, w2=0.22):\n",
    "            '''\n",
    "            Args:\n",
    "              in_dim: The dimension of input data  \n",
    "              n_hidden: The dimension of hidden layer\n",
    "              learning_rate: The initial learning rate for training a network \n",
    "            '''\n",
    "            super().__init__()\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "                nn.BatchNorm1d(in_dim),\n",
    "                nn.Linear(in_dim, n_hidden),\n",
    "                nn.ReLU(), \n",
    "                nn.Linear(n_hidden, n_hidden//2),\n",
    "                nn.Linear(n_hidden//2, 1)\n",
    "                )\n",
    "\n",
    "            self.optim = torch.optim.Adam(self.model.parameters(), betas=(0.9, 0.999), eps=1e-8, lr=learning_rate)\n",
    "            self.mse_loss = nn.MSELoss()\n",
    "            self.l1_loss = nn.L1Loss()\n",
    "            self.bce = nn.BCEWithLogitsLoss()\n",
    "            self.w1 = w1\n",
    "            self.w2 = w2\n",
    "    \n",
    "    def _calculate_loss(self, x, y):\n",
    "        loss =  self.w1*self.mse_loss(x, y) + self.w2*self.l1_loss(x,y)\n",
    "        return loss \n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.model(x)\n",
    "        return z\n",
    "\n",
    "    def train(self, x, y, epochs=1000, batch_size=20):\n",
    "        B = batch_size\n",
    "        n = len(y)\n",
    "        for i in tqdm(range(epochs)):\n",
    "            \n",
    "            for j in range(0, n, B):\n",
    "                if j+B > n:\n",
    "                    m = n-j\n",
    "                    continue\n",
    "                else:\n",
    "                    m=B\n",
    "                 \n",
    "                xi = [v.unsqueeze(0) for v in x[j:(j+m)]]\n",
    "                yi = y[j:(j+m)]\n",
    "                \n",
    "                xi = torch.cat(xi, dim=0)\n",
    "                \n",
    "                pred_y = self.forward(xi)#.reshape(-1)\n",
    "                pred_y = pred_y.reshape(-1)\n",
    "                # print(pred_y.shape, yi.shape)\n",
    "                loss = self._calculate_loss(pred_y, yi)\n",
    "                self.model.zero_grad()\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:  # 여기 나누는 값을 조정해서 프린트하는 횟수를 조절\n",
    "                ppred = self.predict(x_eval_torch)\n",
    "                eval_loss = np.mean((ppred - y_eval)**2)\n",
    "                print(\"epoch {} : err = {:.4f}, eval err = {:.4f}\".format(i + 1, loss, eval_loss))\n",
    "\n",
    "    def predict(self, x):\n",
    "        x, _, _= norm(x, x_train_mean, x_train_std)\n",
    "        output = self.forward(x)\n",
    "        output = dnorm(output, y_train_mean, y_train_std)\n",
    "        output = output.data.cpu().numpy()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset(idxs=[2,3])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)  # 수정 금지 \n",
    "x_train, x_eval, y_train, y_eval = train_test_split(x_train, y_train, test_size=0.125, random_state=999)\n",
    "x_train_torch = torch.FloatTensor(x_train)#.cuda()\n",
    "y_train_torch = torch.FloatTensor(y_train)#.cuda()\n",
    "x_eval_torch = torch.FloatTensor(x_eval)#.cuda()\n",
    "y_eval_torch = torch.FloatTensor(y_eval)#.cuda()\n",
    "x_test_torch = torch.FloatTensor(x_test)#.cuda()\n",
    "y_test_torch = torch.FloatTensor(y_test)#.cuda()\n",
    "x_train_norm, x_train_mean, x_train_std = norm(x_train_torch)\n",
    "y_train_norm, y_train_mean, y_train_std = norm(y_train_torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 122.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 : err = 82.7303, eval err = 3093.1055\n",
      "epoch 20 : err = 1.8106, eval err = 81.6620\n",
      "epoch 30 : err = 1.1924, eval err = 61.0533\n",
      "51.040593618875086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_seed = 222\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "neuron = RegressionNeuron2(in_dim=x_train_norm.shape[-1], n_hidden=32,  learning_rate=1,\n",
    "w1=1.15, w2=0.185,\n",
    ")#.cuda()\n",
    "neuron.train(x_train_norm, y_train_norm, epochs=30, batch_size=64)\n",
    "\n",
    "output = np.mean((neuron.predict(x_test_torch) - y_test)**2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
